{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Processing Buoy 46214\n",
    "\n",
    "Here I will process buoy 46214 using data utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "buoy_num = 46214\n",
    "buoy_str = '46214'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from data_utils.data_processing import *\n",
    "\n",
    "obs_file_46214 = '/home/hutch_research/data/waves/buoys_20190315/CDIPObserved_46214_hourly.mat'\n",
    "ww3_file_46214 = '/home/hutch_research/data/waves/buoys_20190315/WW3CFSRphase2_46214_rebanded.mat'\n",
    "\n",
    "# Generate these for access to timegaps\n",
    "buoy_object = ObservedDatasetFromFile(obs_file_46214)\n",
    "glob_object = WW3DatasetFromFile(ww3_file_46214)\n",
    "\n",
    "# Generate the shared \n",
    "obs_times, ww3_times, buoy_tensor, global_tensor = generate_combined_datasets(obs_file_46214, ww3_file_46214)\n",
    "\n",
    "# just extract the first result\n",
    "obs_times = obs_times[0]\n",
    "ww3_times = ww3_times[0]\n",
    "buoy_tensor = buoy_tensor[0]\n",
    "global_tensor = global_tensor[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyzing times\n",
    "\n",
    "**Let's look at the time ranges we're working with**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "obs start:\t1996-12-06 02:00:00.000003\tend:\t2009-04-19 02:00:00.000003\n",
      "ww3 start:\t1996-12-06 01:59:59.999993\tend:\t2009-04-19 01:59:59.999993\n"
     ]
    }
   ],
   "source": [
    "from data_utils.matlab_datenums import matlab_datenum_to_py_date as mdtm\n",
    "\n",
    "print(\"obs start:\", mdtm(obs_times[0]), \"end:\", mdtm(obs_times[-1]), sep='\\t')\n",
    "print(\"ww3 start:\", mdtm(ww3_times[0]), \"end:\", mdtm(ww3_times[-1]), sep='\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Now we need to analyze the time gaps**\n",
    "A gap is stored as an array of arrays:\n",
    "\n",
    "`[ [[start date, end data], [start index, end index]], \n",
    "   ...\n",
    "   [[start date, end data], [start index, end index]], \n",
    " ]`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of gaps: 11\n",
      "gap: 00   start: 1993-09-01 00:00:00 [0]   end: 1996-12-06 02:00:00.000003 [28610]\n",
      "gap: 01   start: 1997-09-20 12:59:59.999997 [35533]   end: 1997-10-13 21:00:00 [36093]\n",
      "gap: 02   start: 1998-10-21 03:00:00 [45027]   end: 1998-11-04 08:00:00.000003 [45368]\n",
      "gap: 03   start: 1999-09-12 08:00:00.000003 [52856]   end: 1999-10-18 18:59:59.999997 [53731]\n",
      "gap: 04   start: 2002-12-14 18:59:59.999997 [81403]   end: 2003-01-10 18:00:00 [82050]\n",
      "gap: 05   start: 2004-02-12 03:59:59.999997 [91588]   end: 2004-04-11 15:59:59.999997 [93016]\n",
      "gap: 06   start: 2005-10-30 11:00:00.000003 [106619]   end: 2005-11-17 20:00:00.000003 [107060]\n",
      "gap: 07   start: 2007-05-28 04:00:00.000007 [120412]   end: 2007-06-29 20:00:00.000003 [121196]\n",
      "gap: 08   start: 2009-04-19 03:00:00 [137019]   end: 2009-05-21 22:00:00.000007 [137806]\n",
      "gap: 09   start: 2014-09-05 11:00:00.000003 [184187]   end: 2014-10-08 18:00:00 [184986]\n",
      "gap: 10   start: 2015-05-29 05:00:00.000003 [190565]   end: 2015-12-02 18:00:00 [195066]\n"
     ]
    }
   ],
   "source": [
    "# check the buoy time gaps first\n",
    "gaps = buoy_object.time_gaps\n",
    "num_gaps = len(gaps)\n",
    "print(\"Number of gaps:\", num_gaps)\n",
    "\n",
    "for i in range(num_gaps):\n",
    "    cur_gap = gaps[i]\n",
    "    cur_gap_dates = cur_gap[0]\n",
    "    start = mdtm(cur_gap_dates[0])\n",
    "    end = mdtm(cur_gap_dates[1])\n",
    "\n",
    "    start_dtm = str(start.year) + \"-\" + str(start.month).zfill(2) + \"-\" + str(start.day).zfill(2) + \" \" + str(start.hour).zfill(2) + \":\"  + str(start.minute).zfill(2)\n",
    "    end_dtm = str(end.year) + \"-\" + str(end.month).zfill(2) + \"-\" + str(end.day).zfill(2) + \" \" + str(end.hour).zfill(2) + \":\"  + str(end.minute).zfill(2)\n",
    "    \n",
    "    print(\"gap:\", str(i).zfill(2), \"  start:\", start, \"[%d]\" % cur_gap[1][0], \"  end:\", end, \"[%d]\" % cur_gap[1][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of gaps: 0\n"
     ]
    }
   ],
   "source": [
    "# Check the ww3 for time gaps -- it is very unlikely it has them\n",
    "\n",
    "gaps = glob_object.time_gaps\n",
    "num_gaps = len(gaps)\n",
    "print(\"Number of gaps:\", num_gaps)\n",
    "\n",
    "if num_gaps > 0:\n",
    "    for i in range(num_gaps):\n",
    "        cur_gap = gaps[i]\n",
    "        cur_gap_dates = cur_gap[0]\n",
    "        start = mdtm(cur_gap_dates[0])\n",
    "        end = mdtm(cur_gap_dates[1])\n",
    "\n",
    "        start = str(start.year) + \"-\" + str(start.month).zfill(2) + \"-\" + str(start.day).zfill(2) + \" \" + str(start.hour).zfill(2) + \":\"  + str(start.minute).zfill(2)\n",
    "        end = str(end.year) + \"-\" + str(end.month).zfill(2) + \"-\" + str(end.day).zfill(2) + \" \" + str(end.hour).zfill(2) + \":\"  + str(end.minute).zfill(2)\n",
    "\n",
    "        print(\"gap:\", str(i).zfill(2), \"  start:\", start, \"[%d]\" % cur_gap[1][0], \"  end:\", end, \"[%d]\" % cur_gap[1][1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But the shared date range in our dataset is only:\n",
    "\n",
    "`1996-12-06 02:00:00`\tto\t`2009-04-19 02:00:00`\n",
    "\n",
    "*Note that in the data preprocessing `generate_combined_datasets` actually took this into account*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving the dataset to a file\n",
    "\n",
    "I created a method called `save_single_set_to_npz(filename, time_vector, obs_tensor, ww3_tensor, compressed=False)`\n",
    "\n",
    "Typically I would save this with `obs_times` followed by the tensors according to their values.  The problem that I didn't solve early was managing a way to organize these into train, dev, and test.  I'll do a simple save here, and then walk through dividing up the data into train, dev, test.\n",
    "\n",
    "Special note on this --> I also had to create a method later con called `convert_to_third_order_tensor(some_data)`, we'll need this :-\\\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done... saved to data/46214_combined_data_2019-03-29.npz\n"
     ]
    }
   ],
   "source": [
    "outdir = 'data/'\n",
    "suffix = str(datetime.date.today()) + '.npz'\n",
    "filename = outdir + buoy_str + '_combined_data_' + suffix\n",
    "\n",
    "save_single_set_to_npz(filename, obs_times, convert_to_third_order_tensor(buoy_tensor), convert_to_third_order_tensor(global_tensor))\n",
    "\n",
    "print(\"done... saved to \" + filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting up Train, Dev, and Test\n",
    "\n",
    "Now I need to create the Train, Dev, and Test sets.\n",
    "This is going to involve some manual analysis to divide up the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of time entries: 103333\n",
      "\n",
      "6922\t1996-12-06 02:00:00.000003\t1997-09-20 12:00:00\t729365.0833333334\t729653.5\n",
      "15856\t1997-10-13 21:00:00\t1998-10-21 02:00:00.000003\t729676.875\t730049.0833333334\n",
      "23344\t1998-11-04 08:00:00.000003\t1999-09-12 06:59:59.999997\t730063.3333333334\t730375.2916666666\n",
      "51016\t1999-10-18 18:59:59.999997\t2002-12-14 18:00:00\t730411.7916666666\t731564.75\n",
      "60554\t2003-01-10 18:00:00\t2004-02-12 03:00:00\t731591.75\t731989.125\n",
      "74157\t2004-04-11 15:59:59.999997\t2005-10-30 09:59:59.999997\t732048.6666666666\t732615.4166666666\n",
      "87509\t2005-11-17 20:00:00.000003\t2007-05-28 03:00:00\t732633.8333333334\t733190.125\n"
     ]
    }
   ],
   "source": [
    "threshold = 0.04167  # relative threshold between hours: 0.04166666662786156\n",
    "\n",
    "num_times = len(obs_times)\n",
    "print(\"Number of time entries: %d\\n\" % num_times)\n",
    "\n",
    "seq_start = 0\n",
    "seq_end = 0\n",
    "\n",
    "for i in range(len(obs_times) - 1):\n",
    "    cur = obs_times[i]\n",
    "    nxt = obs_times[i + 1]\n",
    "    if nxt - cur > threshold:\n",
    "        seq_end = i\n",
    "        \n",
    "        print(i, mdtm(obs_times[seq_start]), mdtm(obs_times[seq_end]), obs_times[seq_start], obs_times[seq_end], sep='\\t')\n",
    "        seq_start = seq_end + 1\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysis results\n",
    "After doing analysis on this, see the file `data/obs_ww3_stats.ods`.\n",
    "\n",
    "Here are the following allocations:\n",
    "* Train -> idx_range(0:74158)\n",
    "* Dev -> idx_range(74158:87510)\n",
    "* Test -> idx_range(87510:-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "... saved TRAIN: data/46214_waves_TRAIN_2019-03-29.npz\n",
      "... saved DEV: data/46214_waves_DEV_2019-03-29.npz\n",
      "... saved TEST: data/46214_waves_TEST_2019-03-29.npz\n"
     ]
    }
   ],
   "source": [
    "outdir = 'data/'\n",
    "suffix = str(datetime.date.today()) + '.npz'\n",
    "trn_filename = outdir + buoy_str + '_waves_TRAIN_' + suffix\n",
    "dev_filename = outdir + buoy_str + '_waves_DEV_' + suffix\n",
    "tst_filename = outdir + buoy_str + '_waves_TEST_' + suffix\n",
    "\n",
    "trn_beg = 0\n",
    "trn_end = 74158\n",
    "dev_beg = trn_end\n",
    "dev_end = 87510\n",
    "tst_beg = dev_end\n",
    "tst_end = -1\n",
    "\n",
    "# save_single_set_to_npz(filename, obs_times, convert_to_third_order_tensor(buoy_tensor), convert_to_third_order_tensor(global_tensor))\n",
    "\n",
    "buoy_tens3o = convert_to_third_order_tensor(buoy_tensor)\n",
    "glob_tens3o = convert_to_third_order_tensor(global_tensor)\n",
    "\n",
    "# save train\n",
    "save_single_set_to_npz(trn_filename, \n",
    "                       obs_times[trn_beg:trn_end], \n",
    "                       buoy_tens3o[trn_beg:trn_end, :, :], \n",
    "                       glob_tens3o[trn_beg:trn_end, :, :])\n",
    "print(\"... saved TRAIN: \" + trn_filename)\n",
    "\n",
    "# save dev\n",
    "save_single_set_to_npz(dev_filename, \n",
    "                       obs_times[dev_beg:dev_end], \n",
    "                       buoy_tens3o[dev_beg:dev_end, :, :], \n",
    "                       glob_tens3o[dev_beg:dev_end, :, :])\n",
    "print(\"... saved DEV: \" + dev_filename)\n",
    "\n",
    "\n",
    "# save test\n",
    "save_single_set_to_npz(tst_filename, \n",
    "                       obs_times[tst_beg:tst_end],\n",
    "                       buoy_tens3o[tst_beg:tst_end, :, :], \n",
    "                       glob_tens3o[tst_beg:tst_end, :, :])\n",
    "print(\"... saved TEST: \" + tst_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
