{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Processing Buoy 46218\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "buoy_num = 46218\n",
    "buoy_str = '46218B'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_utils.data_processing import *\n",
    "\n",
    "obs_file = '/home/hutch_research/data/waves/buoys_20190315/CDIPObserved_' + buoy_str + '_hourly.mat'\n",
    "ww3_file = '/home/hutch_research/data/waves/buoys_20190315/WW3CFSRphase2_' + buoy_str + '_rebanded.mat'\n",
    "\n",
    "# Generate these for access to timegaps\n",
    "buoy_object = ObservedDatasetFromFile(obs_file)\n",
    "glob_object = WW3DatasetFromFile(ww3_file)\n",
    "\n",
    "# Generate the shared \n",
    "obs_times, ww3_times, buoy_tensor, global_tensor = generate_combined_datasets(obs_file, ww3_file)\n",
    "\n",
    "# just extract the first result\n",
    "obs_times = obs_times[0]\n",
    "ww3_times = ww3_times[0]\n",
    "buoy_tensor = buoy_tensor[0]\n",
    "global_tensor = global_tensor[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyzing times\n",
    "\n",
    "**Let's look at the time ranges we're working with**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "obs start:\t1995-12-01 02:00:00.000003\tend:\t2008-12-14 01:00:00.000007\n",
      "ww3 start:\t1995-12-01 01:59:59.999993\tend:\t2008-12-14 00:59:59.999997\n"
     ]
    }
   ],
   "source": [
    "from data_utils.matlab_datenums import matlab_datenum_to_py_date as mdtm\n",
    "\n",
    "print(\"obs start:\", mdtm(obs_times[0]), \"end:\", mdtm(obs_times[-1]), sep='\\t')\n",
    "print(\"ww3 start:\", mdtm(ww3_times[0]), \"end:\", mdtm(ww3_times[-1]), sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(216936, 64)\n",
      "(90584, 64)\n"
     ]
    }
   ],
   "source": [
    "print(buoy_object.a1.shape)\n",
    "print(glob_object.a1.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Now we need to analyze the time gaps**\n",
    "A gap is stored as an array of arrays:\n",
    "\n",
    "`[ [[start date, end data], [start index, end index]], \n",
    "   ...\n",
    "   [[start date, end data], [start index, end index]], \n",
    " ]`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of gaps: 8\n",
      "gap: 00   start: 1993-09-01 00:00:00 [0]   end: 1995-12-01 02:00:00.000003 [19706]\n",
      "gap: 01   start: 1996-03-15 17:00:00.000003 [22241]   end: 1998-03-19 18:00:00 [39858]\n",
      "gap: 02   start: 1998-09-30 00:59:59.999997 [44521]   end: 1998-10-07 18:00:00 [44706]\n",
      "gap: 03   start: 2004-04-05 00:59:59.999997 [92857]   end: 2004-05-07 23:00:00.000003 [93647]\n",
      "gap: 04   start: 2007-11-07 07:00:00.000007 [124327]   end: 2007-11-27 20:00:00.000003 [124820]\n",
      "gap: 05   start: 2008-12-14 02:00:00.000003 [133994]   end: 2009-02-27 21:00:00 [135813]\n",
      "gap: 06   start: 2010-11-23 20:00:00.000003 [151028]   end: 2010-12-03 19:00:00.000007 [151267]\n",
      "gap: 07   start: 2016-03-03 12:00:00 [197268]   end: 2016-06-03 15:00:00 [199479]\n"
     ]
    }
   ],
   "source": [
    "# check the buoy time gaps first\n",
    "gaps = buoy_object.time_gaps\n",
    "num_gaps = len(gaps)\n",
    "print(\"Number of gaps:\", num_gaps)\n",
    "\n",
    "for i in range(num_gaps):\n",
    "    cur_gap = gaps[i]\n",
    "    cur_gap_dates = cur_gap[0]\n",
    "    start = mdtm(cur_gap_dates[0])\n",
    "    end = mdtm(cur_gap_dates[1])\n",
    "\n",
    "    start_dtm = str(start.year) + \"-\" + str(start.month).zfill(2) + \"-\" + str(start.day).zfill(2) + \" \" + str(start.hour).zfill(2) + \":\"  + str(start.minute).zfill(2)\n",
    "    end_dtm = str(end.year) + \"-\" + str(end.month).zfill(2) + \"-\" + str(end.day).zfill(2) + \" \" + str(end.hour).zfill(2) + \":\"  + str(end.minute).zfill(2)\n",
    "    \n",
    "    print(\"gap:\", str(i).zfill(2), \"  start:\", start, \"[%d]\" % cur_gap[1][0], \"  end:\", end, \"[%d]\" % cur_gap[1][1])\n",
    "    # print(end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of gaps: 0\n"
     ]
    }
   ],
   "source": [
    "# Check the ww3 for time gaps -- it is very unlikely it has them\n",
    "\n",
    "gaps = glob_object.time_gaps\n",
    "num_gaps = len(gaps)\n",
    "print(\"Number of gaps:\", num_gaps)\n",
    "\n",
    "if num_gaps > 0:\n",
    "    for i in range(num_gaps):\n",
    "        cur_gap = gaps[i]\n",
    "        cur_gap_dates = cur_gap[0]\n",
    "        start = mdtm(cur_gap_dates[0])\n",
    "        end = mdtm(cur_gap_dates[1])\n",
    "\n",
    "        start = str(start.year) + \"-\" + str(start.month).zfill(2) + \"-\" + str(start.day).zfill(2) + \" \" + str(start.hour).zfill(2) + \":\"  + str(start.minute).zfill(2)\n",
    "        end = str(end.year) + \"-\" + str(end.month).zfill(2) + \"-\" + str(end.day).zfill(2) + \" \" + str(end.hour).zfill(2) + \":\"  + str(end.minute).zfill(2)\n",
    "\n",
    "        print(\"gap:\", str(i).zfill(2), \"  start:\", start, \"[%d]\" % cur_gap[1][0], \"  end:\", end, \"[%d]\" % cur_gap[1][1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But the shared date range in our dataset is only:\n",
    "\n",
    "`1996-12-06 02:00:00`\tto\t`2009-04-19 02:00:00`\n",
    "\n",
    "*Note that in the data preprocessing `generate_combined_datasets` actually took this into account*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving the dataset to a file\n",
    "\n",
    "I created a method called `save_single_set_to_npz(filename, time_vector, obs_tensor, ww3_tensor, compressed=False)`\n",
    "\n",
    "Typically I would save this with `obs_times` followed by the tensors according to their values.  The problem that I didn't solve early was managing a way to organize these into train, dev, and test.  I'll do a simple save here, and then walk through dividing up the data into train, dev, test.\n",
    "\n",
    "Special note on this --> I also had to create a method later con called `convert_to_third_order_tensor(some_data)`, we'll need this :-\\\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done... saved to data/46218B_combined_data_2019-03-29.npz\n"
     ]
    }
   ],
   "source": [
    "outdir = 'data/'\n",
    "suffix = str(datetime.date.today()) + '.npz'\n",
    "filename = outdir + buoy_str + '_combined_data_' + suffix\n",
    "\n",
    "save_single_set_to_npz(filename, obs_times, convert_to_third_order_tensor(buoy_tensor), convert_to_third_order_tensor(global_tensor))\n",
    "\n",
    "print(\"done... saved to \" + filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting up Train, Dev, and Test\n",
    "\n",
    "Now I need to create the Train, Dev, and Test sets.\n",
    "This is going to involve some manual analysis to divide up the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of time entries: 95203\n",
      "\n",
      "2534\t1995-12-01 02:00:00.000003\t1996-03-15 15:59:59.999997\t728994.0833333334\t729099.6666666666\n",
      "7197\t1998-03-19 18:00:00\t1998-09-30 00:00:00\t729833.75\t730028.0\n",
      "55348\t1998-10-07 18:00:00\t2004-04-05 00:00:00\t730035.75\t732042.0\n",
      "86028\t2004-05-07 23:00:00.000003\t2007-11-07 06:00:00\t732074.9583333334\t733353.25\n",
      "95201\t2007-11-27 20:00:00.000003\t2007-11-07 06:00:00\t733373.8333333334\t733353.25\n"
     ]
    }
   ],
   "source": [
    "threshold = 0.04167  # relative threshold between hours: 0.04166666662786156\n",
    "\n",
    "num_times = len(obs_times)\n",
    "print(\"Number of time entries: %d\\n\" % num_times)\n",
    "\n",
    "seq_start = 0\n",
    "seq_end = 0\n",
    "\n",
    "for i in range(len(obs_times) - 1):\n",
    "    cur = obs_times[i]\n",
    "    nxt = obs_times[i + 1]\n",
    "    if nxt - cur > threshold:\n",
    "        seq_end = i\n",
    "        \n",
    "        print(i, mdtm(obs_times[seq_start]), mdtm(obs_times[seq_end]), obs_times[seq_start], obs_times[seq_end], sep='\\t')\n",
    "\n",
    "        seq_start = seq_end + 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2007-11-27 20:00:00.000003\t2008-12-14 01:00:00.000007\n",
      "733373.8333333334 733756.0416666667\n"
     ]
    }
   ],
   "source": [
    "print(mdtm(obs_times[seq_start]), mdtm(obs_times[-1]), sep='\\t')\n",
    "print(obs_times[seq_start], obs_times[-1])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysis results\n",
    "After doing analysis on this, see the file `data/obs_ww3_stats.ods`.\n",
    "\n",
    "Here are the following allocations:\n",
    "* Train -> idx_range(0:66643)\n",
    "* Dev -> idx_range(66643:80923)\n",
    "* Test -> idx_range(80923:-1)\n",
    "\n",
    "Set\tDatapoints\tStart_idx\tEnd_idx\tDays\n",
    "Train\t66643\t0\t66643\t2776.7916666667\n",
    "Dev\t14280\t66643\t80923\t595\n",
    "Test\t14280\t80923\t-1\t\n",
    "![image.png](attachment:image.png)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "95203"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(obs_times)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "... saved TRAIN: data/46218B_waves_TRAIN_2019-03-29.npz\n",
      "... saved DEV: data/46218B_waves_DEV_2019-03-29.npz\n",
      "... saved TEST: data/46218B_waves_TEST_2019-03-29.npz\n"
     ]
    }
   ],
   "source": [
    "outdir = 'data/'\n",
    "suffix = str(datetime.date.today()) + '.npz'\n",
    "trn_filename = outdir + buoy_str + '_waves_TRAIN_' + suffix\n",
    "dev_filename = outdir + buoy_str + '_waves_DEV_' + suffix\n",
    "tst_filename = outdir + buoy_str + '_waves_TEST_' + suffix\n",
    "\n",
    "trn_beg = 0\n",
    "trn_end = 66643\n",
    "dev_beg = trn_end\n",
    "dev_end = 80923\n",
    "tst_beg = dev_end\n",
    "tst_end = -1\n",
    "\n",
    "# save_single_set_to_npz(filename, obs_times, convert_to_third_order_tensor(buoy_tensor), convert_to_third_order_tensor(global_tensor))\n",
    "\n",
    "buoy_tens3o = convert_to_third_order_tensor(buoy_tensor)\n",
    "glob_tens3o = convert_to_third_order_tensor(global_tensor)\n",
    "\n",
    "# save train\n",
    "save_single_set_to_npz(trn_filename, \n",
    "                       obs_times[trn_beg:trn_end], \n",
    "                       buoy_tens3o[trn_beg:trn_end, :, :], \n",
    "                       glob_tens3o[trn_beg:trn_end, :, :])\n",
    "print(\"... saved TRAIN: \" + trn_filename)\n",
    "\n",
    "# save dev\n",
    "save_single_set_to_npz(dev_filename, \n",
    "                       obs_times[dev_beg:dev_end], \n",
    "                       buoy_tens3o[dev_beg:dev_end, :, :], \n",
    "                       glob_tens3o[dev_beg:dev_end, :, :])\n",
    "print(\"... saved DEV: \" + dev_filename)\n",
    "\n",
    "\n",
    "# save test\n",
    "save_single_set_to_npz(tst_filename, \n",
    "                       obs_times[tst_beg:tst_end],\n",
    "                       buoy_tens3o[tst_beg:tst_end, :, :], \n",
    "                       glob_tens3o[tst_beg:tst_end, :, :])\n",
    "print(\"... saved TEST: \" + tst_filename)\n",
    "\n",
    "\n",
    "# print(\"done... saved to \" + filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
